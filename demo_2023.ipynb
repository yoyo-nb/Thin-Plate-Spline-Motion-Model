{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72cd1d9fd30341abbb80aed2a361e776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bb838094d9147c4b289ac10c9bad2de",
              "IPY_MODEL_578d790d442144b3bc77fa6f3470537e",
              "IPY_MODEL_7ae687f601dd4f00a0de13b03149d37a"
            ],
            "layout": "IPY_MODEL_301fbe6f21b2479098a05a4a2974cfb5"
          }
        },
        "5bb838094d9147c4b289ac10c9bad2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2be8b4fbb034422956db0c9e8e29270",
            "placeholder": "​",
            "style": "IPY_MODEL_bfd804017cf64f3da5f5f9fce2acf716",
            "value": "resizing frames: 100%"
          }
        },
        "578d790d442144b3bc77fa6f3470537e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01227009cdee4dccb448fb709b48510f",
            "max": 2200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13eefda57d35437e9ec92512b67c8fd5",
            "value": 2200
          }
        },
        "7ae687f601dd4f00a0de13b03149d37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3468e79fff345d2843f3c3b509bf2b4",
            "placeholder": "​",
            "style": "IPY_MODEL_75d0952db47347b7b742a641357044df",
            "value": " 2200/2200 [00:36&lt;00:00, 70.27it/s]"
          }
        },
        "301fbe6f21b2479098a05a4a2974cfb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2be8b4fbb034422956db0c9e8e29270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd804017cf64f3da5f5f9fce2acf716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01227009cdee4dccb448fb709b48510f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13eefda57d35437e9ec92512b67c8fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3468e79fff345d2843f3c3b509bf2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d0952db47347b7b742a641357044df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OqNFWx7UDlR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb3d67e-96bf-437f-d57b-9f6070f8ffb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Thin-Plate-Spline-Motion-Model'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 127 (delta 50), reused 32 (delta 30), pack-reused 50\u001b[K\n",
            "Receiving objects: 100% (127/127), 32.66 MiB | 34.98 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "/content/Thin-Plate-Spline-Motion-Model\n"
          ]
        }
      ],
      "source": [
        "#@title # Step 1: Setup\n",
        "\n",
        "import os\n",
        "os.environ['LANG'] = 'en_US.UTF-8'\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "%cd /content\n",
        "if not os.path.isdir('Thin-Plate-Spline-Motion-Model'):\n",
        "    !git clone https://github.com/gee666/Thin-Plate-Spline-Motion-Model.git\n",
        "%cd Thin-Plate-Spline-Motion-Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 2: Load models\n",
        "#@markdown ## uncomment the models you want to use\n",
        "\n",
        "!mkdir checkpoints\n",
        "!pip3 install wldhx.yadisk-direct\n",
        "\n",
        "!curl -L $(yadisk-direct https://disk.yandex.com/d/i08z-kCuDGLuYA) -o checkpoints/vox.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.com/d/vk5dirE6KNvEXQ) -o checkpoints/taichi.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.com/d/IVtro0k2MVHSvQ) -o checkpoints/mgif.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.com/d/B3ipFzpmkB1HIA) -o checkpoints/ted.pth.tar\n",
        "\n",
        "# different source\n",
        "# !curl -L $(yadisk-direct https://disk.yandex.ru/d/YbOdosYEwYY_SA) -o checkpoints/vox.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.ru/d/6eKgFjCUA-7k2w) -o checkpoints/taichi.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.ru/d/PRSRPrSgIExosw) -o checkpoints/mgif.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.ru/d/YbOdosYEwYY_SA) -o checkpoints/ted.pth.tar"
      ],
      "metadata": {
        "id": "X-Bx4QT1UOod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddd2949-1195-4f73-ac5d-718028476499"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wldhx.yadisk-direct\n",
            "  Downloading wldhx.yadisk_direct-0.0.6-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wldhx.yadisk-direct) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wldhx.yadisk-direct) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wldhx.yadisk-direct) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wldhx.yadisk-direct) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wldhx.yadisk-direct) (2023.7.22)\n",
            "Installing collected packages: wldhx.yadisk-direct\n",
            "Successfully installed wldhx.yadisk-direct-0.0.6\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  334M  100  334M    0     0  22.0M      0  0:00:15  0:00:15 --:--:-- 27.1M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 3: Settings\n",
        "#@markdown ##### Import your driving video and/or image before filling in the form\n",
        "#@markdown ##### For best result video and image should be squared 256x256 px\n",
        "\n",
        "\n",
        "import torch\n",
        "import importlib.util\n",
        "import os\n",
        "\n",
        "testmode = False # for testing with little amount of frames\n",
        "max_frames_in_testmode = 16\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "dataset_name = 'vox' #@param {type:\"string\"} ['vox', 'taichi', 'ted', 'mgif']\n",
        "\n",
        "source_image_path = '/content/Thin-Plate-Spline-Motion-Model/assets/source.png' #@param {type:\"string\"}\n",
        "source_image_path = os.path.join(current_directory, source_image_path)\n",
        "source_image_path = os.path.relpath(source_image_path, current_directory)\n",
        "\n",
        "driving_video_path = '/content/Thin-Plate-Spline-Motion-Model/assets/driving.mp4' #@param {type:\"string\"}\n",
        "driving_video_path = os.path.join(current_directory, driving_video_path)\n",
        "driving_video_path = os.path.relpath(driving_video_path, current_directory)\n",
        "\n",
        "output_frames_directory = './output_frames/'\n",
        "output_video_chunks = './video_chunks'\n",
        "output_video_path = './generated.mp4'\n",
        "predict_mode = 'relative' #@param {type:\"string\"}  ['standard', 'relative', 'avd']\n",
        "\n",
        "#@markdown ##### Max batch size will depend on your memory and video size\n",
        "max_batch_size = 2200 #@param { type:\"number\" }\n",
        "\n",
        "fps = 24 # later this value will be corrected\n",
        "if testmode:\n",
        "  max_batch_size = max_frames_in_testmode\n",
        "\n",
        "find_best_frame = False\n",
        "# for relative using find best frame, which can give beeter results\n",
        "if predict_mode == 'relative':\n",
        "  find_best_frame = True\n",
        "  if importlib.util.find_spec('face_alignment') is None:\n",
        "      !pip install face-alignment\n",
        "\n",
        "# for vox, taichi and mgif, the resolution is 256*256\n",
        "pixel = 256\n",
        "# for ted, the resolution is 384*384\n",
        "if(dataset_name == 'ted'):\n",
        "    pixel = 384\n",
        "\n",
        "config_path = f'config/{dataset_name}-{pixel}.yaml'\n",
        "checkpoint_path = f'checkpoints/{dataset_name}.pth.tar'"
      ],
      "metadata": {
        "id": "9x_r_ztKECeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71a7d7d-f8ce-4d92-84f3-57ba8c68e6e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face-alignment\n",
            "  Downloading face_alignment-1.4.1-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from face-alignment) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face-alignment) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.10/dist-packages (from face-alignment) (1.11.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from face-alignment) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from face-alignment) (4.8.0.76)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from face-alignment) (4.66.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from face-alignment) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->face-alignment) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->face-alignment) (67.7.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (3.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->face-alignment) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->face-alignment) (1.3.0)\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 4: Define functions\n",
        "try:\n",
        "  import imageio\n",
        "  import imageio_ffmpeg\n",
        "except:\n",
        "  !pip install imageio_ffmpeg\n",
        "  import imageio\n",
        "  import imageio_ffmpeg\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import warnings\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from skimage import img_as_ubyte\n",
        "import shutil\n",
        "import gc\n",
        "import sys\n",
        "\n",
        "from demo import make_animation\n",
        "from demo import load_checkpoints\n",
        "\n",
        "\n",
        "# Define ensure and clean directory function\n",
        "def prepare_directory(directory_path, clean=True):\n",
        "    \"\"\"\n",
        "    Ensure the directory exists and is empty.\n",
        "\n",
        "    If the directory exists, clear its contents. If not, create the directory.\n",
        "\n",
        "    Parameters:\n",
        "    - directory_path: The path to the directory to prepare.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory_path):\n",
        "        # Directory does not exist, so create it\n",
        "        os.makedirs(directory_path)\n",
        "    elif clean:\n",
        "        # Directory exists, remove any existing files and directories within it\n",
        "        for filename in os.listdir(directory_path):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "\n",
        "def memory_usage():\n",
        "  !echo -n \"Available Memory: \" && cat /proc/meminfo | grep 'MemAvailable' | awk '{print $2/1024 \" MB\"}'\n",
        "\n",
        "\n",
        "def animate(source_image, driving_video):\n",
        "  inpainting, kp_detector, dense_motion_network, avd_network = load_checkpoints(config_path = config_path, checkpoint_path = checkpoint_path, device = device)\n",
        "  if predict_mode=='relative' and find_best_frame:\n",
        "      from demo import find_best_frame as _find\n",
        "      i = _find(source_image, driving_video, device.type=='cpu')\n",
        "      print (\"Best frame: \" + str(i))\n",
        "      driving_forward = driving_video[i:]\n",
        "      driving_backward = driving_video[:(i+1)][::-1]\n",
        "      predictions_forward = make_animation(source_image, driving_forward, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "      predictions_backward = make_animation(source_image, driving_backward, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "      predictions = predictions_backward[::-1] + predictions_forward[1:]\n",
        "  else:\n",
        "      predictions = make_animation(source_image, driving_video, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "  return predictions\n",
        "\n",
        "def process_batch(source_image, reader, total_frames_processed):\n",
        "    driving_video = []\n",
        "\n",
        "    for frame in tqdm(reader, total=reader.count_frames(), desc=\"resizing frames: \"):\n",
        "        frame = resize(frame, (pixel, pixel))[..., :3]\n",
        "        driving_video.append(frame)\n",
        "\n",
        "    memory_usage()\n",
        "    print(\"animating frames...\")\n",
        "    predictions = animate(source_image, driving_video)\n",
        "    memory_usage()\n",
        "\n",
        "    del driving_video\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"saving the batch frames...\")\n",
        "    # Save the resulting frames into the directory \"output_frames_directory\"\n",
        "    for idx, frame in enumerate(predictions):\n",
        "      total_frames_processed += 1\n",
        "      imageio.imsave(f'{output_frames_directory}/frame_{total_frames_processed:04d}.png', img_as_ubyte(frame))\n",
        "    print(f\"...batch saved\")\n",
        "\n",
        "    del predictions\n",
        "    gc.collect()\n",
        "\n",
        "    return total_frames_processed\n",
        "\n",
        "\n",
        "def process_video(source_image):\n",
        "    # List all video part files\n",
        "    video_parts = sorted([file for file in os.listdir(output_video_chunks) if file.endswith('.mp4')])\n",
        "    total_frames_processed = 0\n",
        "\n",
        "    for video_part in video_parts:\n",
        "        video_part_path = os.path.join(output_video_chunks, video_part)\n",
        "        print(f\"Processing video part: {video_part_path}\")\n",
        "\n",
        "        # read the current video part\n",
        "        reader = imageio.get_reader(video_part_path)\n",
        "        fps = reader.get_meta_data()['fps']\n",
        "\n",
        "        # Process the entire part as a single batch\n",
        "        total_frames_processed = process_batch(source_image, reader, total_frames_processed)\n",
        "\n",
        "        reader.close()\n",
        "        del reader\n",
        "        gc.collect()\n",
        "\n",
        "    print(\"_______________________\")\n",
        "    print(f\"Total frames processed: {total_frames_processed}\")\n",
        "    print(\"_______________________\")\n",
        "    memory_usage()\n",
        "\n",
        "\n",
        "\n",
        "def split_video():\n",
        "  # Initialize the video reader\n",
        "  reader = imageio.get_reader(driving_video_path)\n",
        "  global fps\n",
        "  fps=reader.get_meta_data()['fps']\n",
        "\n",
        "  print(\"_______________________\")\n",
        "  print(f\"Total frames count {reader.count_frames()}\")\n",
        "  print(f\"Original fps {fps}\")\n",
        "  print(\"_______________________\")\n",
        "\n",
        "  # Initialize variables\n",
        "  part_number = 1\n",
        "  frame_count = 0\n",
        "  writer = None\n",
        "\n",
        "  # Iterate over frames\n",
        "  for i, frame in enumerate(reader):\n",
        "      # Start a new part if frame_count reached frames_per_part\n",
        "      if frame_count == 0:\n",
        "          if writer:\n",
        "              writer.close()\n",
        "          writer = imageio.get_writer(f'{output_video_chunks}/part_{part_number:02d}.mp4', fps=fps)\n",
        "          part_number += 1\n",
        "\n",
        "      # Write the current frame\n",
        "      writer.append_data(frame)\n",
        "      frame_count += 1\n",
        "\n",
        "      # Reset frame count if it reaches the limit\n",
        "      if frame_count == max_batch_size:\n",
        "          frame_count = 0\n",
        "\n",
        "      # Test mode condition\n",
        "      if testmode and part_number > 1:\n",
        "          break\n",
        "\n",
        "  # Close the last writer\n",
        "  if writer:\n",
        "      writer.close()\n",
        "\n",
        "  del reader, writer\n",
        "  gc.collect()"
      ],
      "metadata": {
        "id": "rA5u3wZCCoBg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 5: Here the magic happens\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "prepare_directory(output_frames_directory)\n",
        "prepare_directory(output_video_chunks)\n",
        "\n",
        "memory_usage()\n",
        "\n",
        "# read the image\n",
        "print(\"Preparing source image...\")\n",
        "source_image = imageio.imread(source_image_path)\n",
        "# Ensure source_image has three channels\n",
        "source_image = resize(source_image, (pixel, pixel))[..., :3]\n",
        "memory_usage()\n",
        "\n",
        "print(\"Splitting the video on chuncs...\")\n",
        "split_video()\n",
        "\n",
        "memory_usage()\n",
        "process_video(source_image)\n",
        "gc.collect()\n",
        "\n",
        "# When all frames are done, combine all the output_frames into the resulting video\n",
        "print(f\"Saving video to {output_video_path}...\")\n",
        "output_frames = sorted(os.listdir(output_frames_directory), key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
        "with imageio.get_writer(output_video_path, fps=fps) as writer:\n",
        "    for frame_filename in output_frames:\n",
        "        frame_path = os.path.join(output_frames_directory, frame_filename)\n",
        "        frame = imageio.imread(frame_path)\n",
        "        writer.append_data(frame)\n",
        "print(\"done!\")\n",
        "\n",
        "del output_frames, source_image\n",
        "gc.collect()\n",
        "memory_usage()"
      ],
      "metadata": {
        "id": "fZeqlpzSLoKg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "72cd1d9fd30341abbb80aed2a361e776",
            "5bb838094d9147c4b289ac10c9bad2de",
            "578d790d442144b3bc77fa6f3470537e",
            "7ae687f601dd4f00a0de13b03149d37a",
            "301fbe6f21b2479098a05a4a2974cfb5",
            "d2be8b4fbb034422956db0c9e8e29270",
            "bfd804017cf64f3da5f5f9fce2acf716",
            "01227009cdee4dccb448fb709b48510f",
            "13eefda57d35437e9ec92512b67c8fd5",
            "a3468e79fff345d2843f3c3b509bf2b4",
            "75d0952db47347b7b742a641357044df"
          ]
        },
        "outputId": "40995bbc-1928-45c0-8a1c-68d5a7b667a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Memory: 11684.1 MB\n",
            "Preparing source image...\n",
            "Available Memory: 11677.4 MB\n",
            "Splitting the video on chuncs...\n",
            "_______________________\n",
            "Total frames count 4294\n",
            "Original fps 30.0\n",
            "_______________________\n",
            "Available Memory: 11651.3 MB\n",
            "Processing video part: ./video_chunks/part_01.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "resizing frames:   0%|          | 0/2200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72cd1d9fd30341abbb80aed2a361e776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Memory: 8361.45 MB\n",
            "animating frames...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n",
            "100%|██████████| 85.7M/85.7M [00:03<00:00, 23.1MB/s]\n",
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/2DFAN4-cd938726ad.zip\" to /root/.cache/torch/hub/checkpoints/2DFAN4-cd938726ad.zip\n",
            " 84%|████████▍ | 77.3M/91.9M [00:25<00:16, 945kB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Commit suicide\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "K8CkfuG6kmXX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}